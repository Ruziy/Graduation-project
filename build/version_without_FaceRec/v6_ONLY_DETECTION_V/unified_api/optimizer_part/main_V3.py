from fastapi import FastAPI, Request, Form
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from enum import Enum
from typing import Literal, Generator
import uvicorn
import subprocess
from ultralytics.utils import LOGGER
import logging
import sys
import re
import time
from pathlib import Path
import cv2
import numpy as np

LOGGER.setLevel(logging.ERROR)

app = FastAPI(title="üß† –£–º–Ω—ã–π API: –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞, –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è, –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏")

BASE_DIR = Path(__file__).resolve().parent
app.mount("/static", StaticFiles(directory=str(BASE_DIR / "static")), name="static")
templates = Jinja2Templates(directory=str(BASE_DIR / "templates"))

def run_base_model_script(model_name: str):
    try:
        script = BASE_DIR / "base.py"
        result = subprocess.run(
            [sys.executable, str(script), "--model", model_name],
            cwd=str(BASE_DIR),
            capture_output=True,
            text=True,
            check=True,
        )
        output_lines = (result.stdout or "").splitlines()
        filtered_lines = []
        in_block = False

        for line in output_lines:
            low = line.lower()
            if re.match(r"=+", line):
                in_block = not in_block
                filtered_lines.append(line)
            elif (
                in_block
                or "–∑–∞–ø—É—Å–∫" in low
                or "–º–æ–¥–µ–ª—å" in low
                or "model" in low
                or "selected" in low
                or "init" in low
                or "starting" in low
            ):
                filtered_lines.append(line)

        filtered_output = "\n".join(filtered_lines).strip()
        if not filtered_output:
            filtered_output = ""

        return {
            "status": "–®—Ç–∞—Ç–Ω—ã–π –∑–∞–ø—É—Å–∫ –∑–∞–≤–µ—Ä—à—ë–Ω",
            "model": model_name,
            "output": f"‚ö†Ô∏è –ê–ª–≥–æ—Ä–∏—Ç–º —à—Ç–∞—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\nüß© –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {model_name}\n{filtered_output}",
        }

    except subprocess.CalledProcessError as e:
        err = (e.stderr or "") + "\n" + (e.stdout or "")
        return {"status": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ base.py", "error": err, "model": model_name}
    except FileNotFoundError as e:
        return {"status": "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", "error": f"{script} ({e})", "model": model_name}


def run_calibration_script(model="insightface", fps_threshold=10.0, cpu_threshold=50.0):
    try:
        script = BASE_DIR / "mecho_algo_V2.py"
        result = subprocess.run(
            [sys.executable, str(script),
             "--model", model,
             "--fps_threshold", str(fps_threshold),
             "--cpu_threshold", str(cpu_threshold)],
            cwd=str(BASE_DIR),
            capture_output=True,
            text=True,
            check=True,
        )

        output_lines = result.stdout.splitlines()
        calibration_lines = []
        in_block = False
        for line in output_lines:
            if re.match(r"=+", line):
                in_block = not in_block
                calibration_lines.append(line)
            elif (
                in_block
                or "–ê–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å" in line
                or "–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ" in line
                or "–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞" in line
                or "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã" in line
                or "–ü–µ—Ä–µ–π–¥—ë–º –∫ –±–æ–ª–µ–µ –ª—ë–≥–∫–æ–π –º–æ–¥–µ–ª–∏" in line
                or "–ø–æ–¥–æ–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–µ —É–¥–∞–ª–æ—Å—å" in line
                or "–¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ" in line
                or "–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å:" in line
                or "–°—Ä–µ–¥–Ω–∏–π FPS" in line
                or "–°—Ä–µ–¥–Ω—è—è –∑–∞–≥—Ä—É–∑–∫–∞ CPU" in line
            ):
                calibration_lines.append(line)

        filtered_output = "\n".join(calibration_lines)

        success = bool(re.search(r"(–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ|–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ)", filtered_output))
        failure = bool(re.search(r"(–ø–æ–¥–æ–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–µ —É–¥–∞–ª–æ—Å—å|–¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ .* –Ω–µ –Ω–∞–π–¥–µ–Ω–æ)", filtered_output))

        model_match = re.search(r"(–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å|–ú–æ–¥–µ–ª—å —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—â–∞—è —É—Å–ª–æ–≤–∏—è–º):\s*([^\n\r]+)", filtered_output)
        avg_fps_match = re.search(r"–°—Ä–µ–¥–Ω–∏–π FPS:\s*([0-9]+(?:\.[0-9]+)?)", filtered_output)
        avg_cpu_match = re.search(r"–°—Ä–µ–¥–Ω—è—è –∑–∞–≥—Ä—É–∑–∫–∞ CPU:\s*([0-9]+(?:\.[0-9]+)?)%", filtered_output)

        payload = {
            "status": "–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞" if success and not failure else (
                      "–ü–æ–¥—Ö–æ–¥—è—â–∏—Ö –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ" if failure else "–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞"),
            "output": filtered_output
        }
        if model_match:
            payload["model"] = model_match.group(2).strip()
        if avg_fps_match:
            payload["avg_fps"] = float(avg_fps_match.group(1))
        if avg_cpu_match:
            payload["avg_cpu"] = float(avg_cpu_match.group(1))

        return payload

    except subprocess.CalledProcessError as e:
        err = (e.stderr or "") + "\n" + (e.stdout or "")
        return {"status": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å–∫—Ä–∏–ø—Ç–∞", "error": err}
    except FileNotFoundError as e:
        return {"status": "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", "error": f"{script} ({e})"}


def run_optimization_script():
    script = BASE_DIR / "algo_V4_fps.py"
    try:
        result = subprocess.run(
            [sys.executable, str(script)],
            cwd=str(BASE_DIR),
            capture_output=True,
            text=True,
            check=False, 
        )

        stdout = (result.stdout or "")
        stderr = (result.stderr or "")

        noise_patterns = [
            re.compile(r"^\s*$"),
            re.compile(r"^utf-?8$", re.IGNORECASE),
            re.compile(r"^Applied providers:"),
            re.compile(r"^find model:\s", re.IGNORECASE),
            re.compile(r"^set det-size:", re.IGNORECASE),
            re.compile(r"^\s*\d+:\s+\d+x\d+\s"),  
            re.compile(r"^Speed:\s"),              
            re.compile(r".*CPUExecutionProvider.*"),
            re.compile(r"^I tensorflow/|^W tensorflow/|^E tensorflow/", re.IGNORECASE),
        ]

        def is_noise(line: str) -> bool:
            s = line.strip()
            return any(rx.search(s) for rx in noise_patterns)

        filtered_lines = [ln for ln in stdout.splitlines() if not is_noise(ln)]

        if result.returncode != 0:
            return {
                "status": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
                "output": "‚ö†Ô∏è –ê–ª–≥–æ—Ä–∏—Ç–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
            }

        if not filtered_lines:
            return {
                "status": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
                "output": "‚ö†Ô∏è –ê–ª–≥–æ—Ä–∏—Ç–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
            }

        return {
            "status": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞",
            "output": "\n".join(filtered_lines),
        }

    except subprocess.CalledProcessError:
        return {
            "status": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
            "output": "‚ö†Ô∏è –ê–ª–≥–æ—Ä–∏—Ç–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
        }
    except FileNotFoundError as e:
        return {"status": "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", "error": f"{script} ({e})"}

class ModeEnum(int, Enum):
    calibrate = 1
    optimize = 2
    select_model = 3

class ModeRequest(BaseModel):
    mode: ModeEnum

class ModelChoice(BaseModel):
    selected_model_name: Literal[
        "yolov8", "insightface", "dlib", "mtcnn",
        "retinaface", "mediapipe", "haarcascade", "ssd"
    ]

selected_model = {"current": None}

@app.get("/", response_class=HTMLResponse)
def home(request: Request):
    return templates.TemplateResponse(
        "index.html",
        {"request": request, "current_model": selected_model["current"]}
    )

@app.post("/select-model-ui")
def select_model_ui(request: Request, model_name: str = Form(...)):
    selected_model["current"] = model_name
    result = run_base_model_script(model_name)
    if isinstance(result, dict):
        result["selected_model"] = model_name
    else:
        result = {
            "status": "–®—Ç–∞—Ç–Ω—ã–π –∑–∞–ø—É—Å–∫ –∑–∞–≤–µ—Ä—à—ë–Ω",
            "output": str(result),
            "selected_model": model_name,
        }
    return templates.TemplateResponse(
        "index.html",
        {"request": request, "result": result, "current_model": selected_model["current"]}
    )



@app.get("/run-mode-ui", response_class=HTMLResponse)
def run_mode_get(request: Request):
    return templates.TemplateResponse(
        "index.html",
        {"request": request, "current_model": selected_model["current"], "view": "run"}
    )

@app.post("/run-mode-ui")
def run_mode_ui(
    request: Request,
    mode: int = Form(...),
    fps_threshold: float = Form(10.0),
    cpu_threshold: float = Form(50.0),
):
    if mode == 1:
        model = "insightface" 
        result = run_calibration_script(model, fps_threshold, cpu_threshold)
    elif mode == 2:
        result = run_optimization_script()
    elif mode == 3:
        model_map = {
            "yolov8": "yolov8",
            "dlib": "dlib",
            "mtcnn": "mtcnn",
            "insightface": "insightface",
            "retinaFace": "retinaface",
            "mediapipe": "mediapipe",
            "haarcascade": "haarcascade",
            "ssd": "ssd",
        }
        selected = selected_model["current"]
        if selected is None or selected not in model_map:
            result = {
                "status": "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ /select-model-ui",
                "available_models": list(model_map.keys()),
            }
        else:
            model_name = model_map[selected]
            result = run_base_model_script(model_name)
    else:
        result = {"error": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ä–µ–∂–∏–º"}

    return templates.TemplateResponse(
        "index.html",
        {"request": request, "result": result, "current_model": selected_model["current"]}
    )

@app.post("/select-model-ui")
def select_model_ui(request: Request, model_name: str = Form(...)):
    selected_model["current"] = model_name
    result = run_base_model_script(model_name)
    result.update({"selected_model": model_name})
    return templates.TemplateResponse(
        "index.html",
        {"request": request, "result": result, "current_model": selected_model["current"]}
    )

def mjpeg_generator(cam_index: int = 0) -> Generator[bytes, None, None]:
    cap = cv2.VideoCapture(cam_index)
    if not cap.isOpened():
        frame = np.zeros((240, 320, 3), dtype=np.uint8)
        cv2.putText(frame, "Camera not available", (10, 120),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2, cv2.LINE_AA)
        ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
        yield (b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" + buf.tobytes() + b"\r\n")
        return

    prev = time.time()
    try:
        while True:
            ok, frame = cap.read()
            if not ok:
                break

            now = time.time()
            fps = 1.0 / max(1e-3, (now - prev))
            prev = now
            hud = f"Model: {selected_model['current'] or '-'}  FPS: {fps:.1f}"
            cv2.putText(frame, hud, (10, 26), cv2.FONT_HERSHEY_SIMPLEX,
                        0.7, (20, 220, 20), 2, cv2.LINE_AA)

            ok, buf = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
            if not ok:
                continue
            chunk = buf.tobytes()
            yield (b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" + chunk + b"\r\n")
            time.sleep(0.01)
    finally:
        cap.release()

@app.get("/stream.mjpg")
def stream_mjpg():
    return StreamingResponse(
        mjpeg_generator(cam_index=0),
        media_type="multipart/x-mixed-replace; boundary=frame"
    )

@app.get("/preview", response_class=HTMLResponse)
def preview_page(request: Request):
    html = f"""
    <!doctype html>
    <html><head>
      <meta charset="utf-8"/>
      <title>Optimizer Preview</title>
      <style>
        body{{font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial;margin:0;padding:16px;background:#0b0b0b;color:#eee}}
        .wrap{{max-width:980px;margin:0 auto}}
        img{{max-width:100%;border:1px solid #333;border-radius:8px;display:block}}
        .row{{display:flex;gap:12px;align-items:center;margin-bottom:12px}}
        .pill{{padding:6px 10px;border:1px solid #333;border-radius:999px;background:#111}}
        a{{color:#9ad}}
      </style>
    </head><body>
      <div class="wrap">
        <div class="row">
          <div class="pill">model: <b>{selected_model['current'] or "‚Äî"}</b></div>
          <div class="pill"><a href="/optimizer/">Back to UI</a></div>
        </div>
        <img src="/optimizer/stream.mjpg" alt="MJPEG stream"/>
      </div>
    </body></html>
    """
    return HTMLResponse(html)

if __name__ == "__main__":
    uvicorn.run("main_V3:app", host="0.0.0.0", port=8010, reload=True)
